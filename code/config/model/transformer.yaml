model_name: "transformer"

# Embedding cfg
embedding_dim: 128

# Transformer cfg
n_layers: 4
model_in: 128    # Embedding.py will modify this cfg automatically
attention_hid: 128
n_heads: 4
ff_hid: 512


# train config
use_GPU: True
gpu_id: 1

EPOCH: 10
batch_size: 24
k_fold: 5
lr: 5e-3
weight_decay: 1e-3