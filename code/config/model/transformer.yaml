model_name: "transformer"

# Embedding cfg
embedding_dim: 512

# Transformer cfg
n_layers: 6
model_in: 512    # Embedding.py will modify this cfg automatically
attention_hid: 128
n_heads: 6
ff_hid: 1024


# train config
use_GPU: True
gpu_id: 0

EPOCH: 10
batch_size: 32
k_fold: 5
lr: 3e-4
weight_decay: 1e-3